{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Say we want to perform a test to detect the presence or absence of some condition. For example, we might want to detect whether someone has fallen victim to some imaginary disease, like CORVID-18 (a rare witch-induced fugue-state that convinced sufferers they were crows, discovered in 1618).\n",
    "\n",
    "We can divide all elements (people, say) into two sets: \n",
    "\n",
    "* +ve (crow-believers) **CROW**\n",
    "* -ve (unwitched) **NORMAL**\n",
    "\n",
    "We can then administer the test to an element -- perhaps pushing a victim off a high ledge and seeing if they flap their \"wings\" -- and we will get either:\n",
    "\n",
    "* a +ve result **FLAP** or\n",
    "* a -ve result **SCREAM**. \n",
    "\n",
    "Since tests are not reliable (some of the unwitched will still flap their arms like wings, some crow-infected will be too shocked to try) we will have to work out how likely it was the element was truly +ve given the test result. It's not like we can push them off a ledge again.\n",
    "\n",
    "The usefulness of this test can be characterised in many ways:\n",
    "\n",
    "* How likely is it that I'm a sufferer if I test positive? P(**CROW**|**FLAP**)\n",
    "* What percentage of the population will test negative? P(**SCREAM**)\n",
    "\n",
    "These questions can be boiled down to three critical dimensions. Although there are many ways to characterise them, we will use:\n",
    "\n",
    "* **sensitivity** \n",
    "* **specificity**\n",
    "* **base rate** proportion the total population that are +ve\n",
    "\n",
    "It will also be important how big the population is in total $N$, and how large any samples we take of this population $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Every test/scenario combination corresponds to a 3-tuple $T=(b, e, p)$: (**b**ase rate, s**e**nsitivity, s**p**ecificity). With those three numbers, we can transform to or from any other representation of test reliability (like precision, recall, false negative rate, etc.)\n",
    "\n",
    "These points correspond to coordinates in a unit cube with bottom left corner on the axes at (0,0,0), stretching to (1,1,1). Every test pair $(e,p)$ represents a horizontal line in this space. Every condition base rate $b$ represents a plane in this space.\n",
    "\n",
    "\n",
    "### Remapping coordinates\n",
    "We are rarely interested in problems where the condition is highly prevalent, and most elements are positive (and we can always switch the polarity of our condition if we need to, and test for **NOT-A-CROW** instead). Likewise, we are unlikely to bother with a test which is extremely unreliable, and thus has sensitivity or specificity <50% (though we might encounter them).\n",
    "\n",
    "This means we will typically have:\n",
    "* sensitivity, less than but very close to 1.0\n",
    "* specificity, less than but very close to 1.0\n",
    "* base rate, positive and very close to 0.0\n",
    "\n",
    "To visualise things more clear, we will remap these values using a kind of logit (log-odds) transform.\n",
    "\n",
    "$$\\text{logit}{(p)} = \\log\\left({\\frac{p}{1-p}}\\right)$$\n",
    "\n",
    "We'll modify it slightly so that all values are mapped in the range $[0, \\infty]$ using a function $\\text{nl}(p)$. \n",
    "\n",
    "* Probabilities < 0.5 (odds greater than 1:1) are mapped to themselves [0, 0.5]\n",
    "* Probabilities > 0.5 (odds less than 1:1) are mapped to base 10 logits,  so that 0.5=1:1, 10=1:10, 20=1:100, 30=1:1000 and so on.\n",
    "\n",
    "We will remap base rate to (1-base rate), so our tuple is transformed to:\n",
    "\n",
    "$$T_n = (\\text{nl}(1-b), \\text{nl}(e), \\text{nl}(p))$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def logit_curve(p):\n",
    "    return np.where(p<0.5, p, 10 * np.log10(p / (1-p)) + 0.5)\n",
    "\n",
    "def inv_logit_curve(p):\n",
    "    q = (p - 0.5) / 0.7\n",
    "    return np.where(p<0.5, p, (10**q)/(10**q+1))\n",
    "\n",
    "\n",
    "def logit_curve(p):\n",
    "    return 10 * np.log10(p / (1-p))\n",
    "\n",
    "def inv_logit_curve(p):\n",
    "    q = p /10.0\n",
    "    return (10**q)/(10**q+1)\n",
    "\n",
    "def n_to_1(p):\n",
    "    if p < 0.5:        \n",
    "        return f\"{(1-p) / (p):.0f}:1\"\n",
    "    else:   \n",
    "        return f\"1:{(p) / (1-p):.0f}\"\n",
    "    \n",
    "print(n_to_1(0.001))\n",
    "\n",
    "ps = np.linspace(0,1,200)\n",
    "plt.plot(ps, logit_curve(ps))\n",
    "\n",
    "def tn(b, e, p):\n",
    "    return logit_curve(1-b), logit_curve(e), logit_curve(p)\n",
    "\n",
    "print(logit_curve(np.array([0.25, 0.5, 0.9, 0.99, 0.999, 0.99999])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp(b, e, p):\n",
    "    return  b * e\n",
    "\n",
    "def fp(b, e, p):\n",
    "    return  (1-b) * (1-p)\n",
    "\n",
    "def fn(b, e, p):\n",
    "    return  b * (1-e)\n",
    "\n",
    "def tn(b, e, p):\n",
    "    return (1-b) * p\n",
    "\n",
    "def ppv(tp, fp, fn, tn):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def npv(tp, fp, fn, tn):\n",
    "    return tn / (fn + tn)\n",
    "\n",
    "\n",
    "e = inv_logit_curve(10.0)\n",
    "p = inv_logit_curve(10.0)\n",
    "b = 1-inv_logit_curve(2.0)\n",
    "\n",
    "logit_curve(npv(tp(b,e,p), fp(b,e,p), fn(b,e,p), tn(b,e,p)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "pn.extension('vtk')\n",
    "print(pn.pane.vtk.enums.PRESET_CMAPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "drange = np.linspace(0, 40, 50).astype(np.float32)\n",
    "\n",
    "dx, dy, dz = np.meshgrid(drange, drange, drange)\n",
    "\n",
    "b, e, p = 1-inv_logit_curve(dx), inv_logit_curve(dy), inv_logit_curve(dz)\n",
    "\n",
    "data_matrix =npv(tp(b,e,p), fp(b,e,p), fn(b,e,p), tn(b,e,p))\n",
    "\n",
    "pn.pane.VTKVolume(data_matrix, sizing_mode='stretch_width', height=400, spacing=(1,1,1), colormap='Plasma (matplotlib)', \n",
    "                  interpolation='nearest', edge_gradient=0, sampling=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
