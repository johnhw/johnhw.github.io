<meta charset="utf-8"> 

# Hashlife
![-](imgs/header.png)

The [Hashlife algorithm](https://en.wikipedia.org/wiki/Hashlife) was invented by Bill Gosper in [#Gosper1984] to speed up evaluation of the Game of Life using a hierarchical caching method. 
It is a very ingenious algorithm and one that has some subtlety in implemention. There are several good explanations on the web, including [Tomas Rokicki's Dr. Dobbs article](https://www.drdobbs.com/jvm/an-algorithm-for-compressing-space-and-t/184406478) and [Jenny Owen's explanation](https://jennyhasahat.github.io/hashlife.html). 

## Game of Life algorithms

There are a huge number of clever ways to implement Conway's Game of Life, from the naive grid counting implementation, to [super fast bit-fiddling like Tony Finch's version](http://dotat.at/prog/life/life.html), to algorithms that rewrite GoL as a different 2x2 16-state automata and simulate that instead and only compute four neighbours instead of nine, like [Callahan's algorithm](https://github.com/johnhw/glgol). There are [asynchronous update algorithms](https://www.researchgate.net/publication/222758581_Asynchronous_game_of_life) and, of course, [implementations in the Game of Life itself](https://www.conwaylife.com/wiki/Unit_cell).

If we have a collection of "on" cells as `(x,y)` pairs, a tiny Python program to compute the next state is:

```python
from collections import Counter
def life(pts):    
    ns = Counter([(x+a, y+b) for x,y in pts for a in [-1,0,1] for b in [-1,0,1]])
    return Counter([p for p in ns if ns[p]==3 or (ns[p]==4 and p in pts)])
```

This implementation has no limits on universe size, other than memory limitations.

The Game of Life is also easy to write as a convolution of a binary matrix, for example with Scipy:

```python
from scipy.ndimage import convolve
k = np.array([1,1,1,1,2,1,1,1,1]).reshape(3,3)
def life(cells):
    result = convolve(cells, k, mode="wrap")
    cells = np.where((result>4) & (result<8), 1, 0) 
```

This is a very simple form to parallelise, e.g. on the GPU.

## Purpose

We want to be able to evaluate a cellular automaton quickly, by pre-caching successors to states we have seen before. To make this efficient, we can cache things hierarchically, in quadtree using a hierarchy over both space and time.

## Algorithm

Assume we have a quadtree, where the children of a node are named ABCD:

**************
*    A B     *
*    C D     *
**************

If we can compute the successor of the "central" block of this node, we can always scan the entire quadtree to compute the complete successor of the quadtree, padding with zeros as needed:


**********************************************************************
* +-----+       |   +-----+        |     +-----+   |       
* | 0 0 | 0 0   | 0 | 0 0 | 0      | 0 0 | 0 0 |   |
* | 0 A | B X   | 0 | A B | X      | 0 A | B X |   |    ...
* +-----+       |   +-----+        |     +-----+   |       
*   0 C   D X   | 0   C  D  X      | 0 C   D X     |
*   0 X   X X   | 0   X  X  X      | 0 X   X X     |
**********************************************************************


We can split a quadtree node into grandchildren (4x4 grid of grandchildren)

****************************
* AA    AB      BA      BB *
*     +------------+       *
* AC  | AD      BC |    BD *
*     |            |       *
* CA  | CB      DA |    DB *
*     +------------+       *
* CC    CD      DC      DD *
****************************

we want to compute the successor of the central region, that is what will be in:

***********
*  ad bc  *
*  cb da  *
***********

in the future (lowercase to indicate the "successor of"). 

We can further split a node into great grandchildren (8x8 grid of great grand children)

*********************************************************************
* AAA   AAB     ABA     ABB         BAA     BAB     BBA     BBB     *
* AAC   AAD     ABC     ABD         BAC     BAD     BBC     BBD     *
*                                                                   *
*            +----------------------------------+                   *
* ACA   ACB  |  ADA     ADB         BCA     BCB |   BDA     BDB     *
* ACC   ACD  |  ADC     ADD         BCC     BCD |   BDC     BDD     *
*            |                                  |                   *
*            |                                  |                   *
* CAA   CAB  |  CBA     CBB         DAA     DAB |   DBA     DBB     *
* CAC   CAD  |  CBC     CBD         DAC     DAD |   DBC     DBD     *
*            +----------------------------------+                   *
*                                                                   *
* CCA   CCB     CDA     CDB         DCA     DCB     DDA     DDB     *
* CCC   CCD     CDC     CDD         DCC     DCD     DDC     DDD     *
*********************************************************************


Now we can find a way to split up the grandchildren of a node
into nine overlapping child-size blocks so that we can compute successors of the size of the grandchildren.
We then subdivide those successor blocks into great-grandchildren
(lowercase indicates successor)

*********************************************************************
*         ╭1╌╌╌╌╌╌╌╮             ╭2╌╌╌╌╌╌╮             ╭3╌╌╌╌╌╌╌╮   *
*AA AB -->╎aad  abc╎    AB BA -->╎abd bac╎   BA BB  -->╎bad  bbc╎   *
*         ╎    +---╎-------------╎-------╎-------------╎---+    ╎   *
*AC AD    ╎acb |ada╎    AD BC    ╎adb bca╎   BC BD     ╎bcb| bda╎   *
*         ╰╌╌╌╌╌╌╌╌╯             ╰╌╌╌╌╌╌╌╯             ╰╌╌╌╌╌╌╌╌╯   *
*              |                                           |        *
*         ╭4╌╌╌╌╌╌╌╮             ╭5╌╌╌╌╌╌╮             ╭6╌╌╌╌╌╌╌╮   *
*AC AD -->╎acd |adc╎    AD BC -->╎add bcc╎   BC BD  -->╎bcd| bdc╎   *
*         ╎    |   ╎             ╎       ╎             ╎   |    ╎   *
*CA CB    ╎cab |cba╎    CB DA    ╎cbb daa╎   DA DB     ╎dab| dba╎   *
*         ╰╌╌╌╌╌╌╌╌╯             ╰╌╌╌╌╌╌╌╯             ╰╌╌╌╌╌╌╌╌╯   *
*              |                                           |        *
*         ╭7╌╌╌╌╌╌╌╮             ╭8╌╌╌╌╌╌╮             ╭9╌╌╌╌╌╌╌╮   *
*CA CB -->╎cad |cbc╎    CB DA -->╎cbd dac╎   DA DB  -->╎dad| dbc╎   *
*CC CD    ╎    +---╎-------------╎-------╎-------------╎---+    ╎   *
*         ╎ccb  cda╎    CD DC    ╎cdb dca╎   DC DD     ╎dcb  dda╎   *
*         ╰╌╌╌╌╌╌╌╌╯             ╰╌╌╌╌╌╌╌╯             ╰╌╌╌╌╌╌╌╌╯   *
*                                                                   *
*********************************************************************

Finally, we can select from those great-grandchildren sized
successor blocks the "inner" parts to make up one full child-sized successor
(a 4x4 block of great-grandchild successors)

************************************************************************
*  +-----------------+     +-----------------+                         *
*  |1:D 2:C | 2:D 3:C|     |ada adb ╎ bca bcb|        +-----+          *
*  |4:B 5:A | 5:B 6:A|     |adc add ╎ bcc bcd|        |ad bc|      +-+ *
*  |-----------------| --> |╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌|    --> |     |  --> |N| *  
*  |4:D 5:C | 5:D 6:C|     |cba cbb ╎ daa dab|        |cb da|      +-+ *
*  |7:B 8:A | 8:B 9:A|     |cbc cbd ╎ dac dad|        +-----+          *
*  +-----------------+     +-----------------+                         *
************************************************************************

To terminate the recursion, at the base level, If we have a $k=2$ 4x4 block, we can compute the 2x2 central successor by iterating over all the 3x3 sub-neighbourhoods of 1x1 cells using the standard Life rule (or any other Moore-neighbourhood binary cellular automaton rule we choose):

*********************************************************
* +-----------+              |     +------------+
* |AA  AB  BA | BB           |  AA | AB  BA  BB |
* |AC  AD  BC | BD  --> ad   |  AC | AD  BC  BD | --> bc
* |CA  CB  DA | DB           |  CA | CB  DA  DB |
* +-----------+              |     +------------+
* CC   CD   DC  DD           |  CC   CD  DC  DD
*----------------------------+------------------------------
*  AA  AB  BA  BB            |  AA   AB  BA  BB 
* +------------+             |     +------------+
* | AC  AD  BC | BD          |  AC | AD  BC  BD | 
* | CA  CB  DA | DB  --> cb  |  CA | CB  DA  DB | --> da
* | CC  CD  DC | DD          |  CC | CD  DC  DD |
* +------------+             |     +------------+
**********************************************************



## Levels

Each node has a **level** $k$, where the size of the node is $2^k \times 2^k$.

* level 0 is a 1x1 block which are just binary values
* level 1 is a 2x2 block whose children are level 0 blocks
* level 2 is 4x4 block whose children are level 1 blocks
* level 3 is an 8x8 block whose children are level 2 blocks
* etc.

It doesn't matter much if the basic Life algorithm is slow. We can use basic brute-force, computing the 2x2 successor of a 4x4 cell by straightforward computation.


## Datastructures

* A **quadtree** `qtree` representing the state of the world at step $t$. Each element is a node `node(k, a, b, c, d, n, hash)`, where `n` is the number of on cells in this node (useful for bookkeeping and display) and `hash` is a precomputed hash of this node -- if we don't do this, Python will recursively compute the hash every time it is needed!

```python
from collections import namedtuple
_Node = namedtuple("Node", ["k", "a", "b", "c", "d", "n", "hash"])

class Node(_Node):    
     def __hash__(self):
        return self.hash
    
     def __repr__(self):
        # print nicely
        return f"Node k={self.k}, {1&lt;&lt;self.k} x {1&lt;&lt;self.k}, population {self.n}"
        
```

We have two base level cells, `on` and `off`

```python
# base level binary nodes
on = Node(0, None, None, None, None, 1, 1)
off = Node(0, None, None, None, None, 0, 0)
```

Everything else is handled using `lru_cache` from `functools` which gives us an automatically garbage-collected and size-limited cache.

## Functions

* **join(a,b,c,d)** combine four children at level `k-1` to a new node at level `k`. If this turns out to be a cached node, return the cached node. Otherwise, create a new node, and add it to the cache.

*********************************************         
*             +-------+
*             | A   B |      +-+
*             |       |  --> |N|
*             | C   D |      +-+
*             +-------+
*********************************************   

We can use the [least recently used cache](https://docs.python.org/3/library/functools.html) to automatically cache results, so we eliminate repeated nodes:

```python
from functools import lru_cache

@lru_cache(maxsize=2**24)
def join(a, b, c, d):        
    n = a.n + b.n + c.n + d.n
    nhash = (
            a.k + 2 +
            + 5131830419411 * a.hash + 3758991985019 * b.hash
            + 8973110871315 * c.hash + 4318490180473 * d.hash
        ) & ((1 << 63) - 1)    
    return Node(a.k + 1, a, b, c, d, n, nhash) 
```

The hashing constants are arbitrary.


* **get_zero(k)** return an empty node at level `k`

```python
@lru_cache(maxsize=1024)
def get_zero(k):
    return off if k==0 else join(get_zero(k - 1), get_zero(k - 1), 
                                 get_zero(k - 1), get_zero(k - 1))    
```

* **centre(node)**  return a node at level `k+1`, which is centered on the given quadtree node:

*****************************************************
*                           +----------------+
*                           | 0   0    0   0 |
*                           |                |
*  +---------+              | 0   A    B   0 |
*  | A    B  |              |                |
*  |         |    -->       | 0   C    D   0 |
*  | C    D  |              |                |
*  +---------+              | 0   0    0   0 |
*                           +----------------+
*****************************************************

```python
def centre(m):
    z = get_zero(m.k - 1)  
    return join(
        join(z, z, z, m.a), join(z, z, m.b, z),
        join(z, m.c, z, z), join(m.d, z, z, z)
    )
```      

* **life_4x4(node)** return the next generation of a $k=2$ (i.e. 4x4) cell. This is the base case of the recursion. It is slow, but this doesn't matter as it will only be called a constant number of times at most.

```python

# life rule, for a 3x3 collection of cells, where E is the centre
def life(a, b, c, d, E, f, g, h, i):
    outer = sum([t.n for t in [a, b, c, d, f, g, h, i]])
    return on if (E.n and outer == 2) or outer == 3 else off

def life_4x4(m):
    na = life(m.a.a, m.a.b, m.b.a, m.a.c, m.a.d, m.b.c, m.c.a, m.c.b, m.d.a)  
    nb = life(m.a.b, m.b.a, m.b.b, m.a.d, m.b.c, m.b.d, m.c.b, m.d.a, m.d.b)  
    nc = life(m.a.c, m.a.d, m.b.c, m.c.a, m.c.b, m.d.a, m.c.c, m.c.d, m.d.c)  
    nd = life(m.a.d, m.b.c, m.b.d, m.c.b, m.d.a, m.d.b, m.c.d, m.d.c, m.d.d)  
    return join(na, nb, nc, nd)

```

* **successor(node)** return the central successor of a node at time $t+2^{k-2}$, either from the successor cache, or by the recursive rules set out above (caching the result).
******************************************************************************************         
*             +-----------+             
*             | A      B  |           .. .. .. ..  
*             |           |             +-----+   
*             |           |  -->      ..|ad bc|..  
*             | C      D  |           ..|cb da|.. 
*             |           |             +-----+   
*             +-----------+           .. .. .. .. 
******************************************************************************************         


To compute one generation ahead, we could apply the rule given above:

```python
@lru_cache(maxsize=2**20)
def next_gen(m):
    """Return the 2**k-1 x 2**k-1 successor, 1 generation forward"""    
    if m.n==0: # empty
        return m.a    
    elif m.k == 2:  # base case               
        s = life_4x4(m)    
    else:
        c1 = next_gen(join(m.a.a, m.a.b, m.a.c, m.a.d))
        c2 = next_gen(join(m.a.b, m.b.a, m.a.d, m.b.c))
        c3 = next_gen(join(m.b.a, m.b.b, m.b.c, m.b.d))
        c4 = next_gen(join(m.a.c, m.a.d, m.c.a, m.c.b))        
        c5 = next_gen(join(m.a.d, m.b.c, m.c.b, m.d.a))
        c6 = next_gen(join(m.b.c, m.b.d, m.d.a, m.d.b))
        c7 = next_gen(join(m.c.a, m.c.b, m.c.c, m.c.d))
        c8 = next_gen(join(m.c.b, m.d.a, m.c.d, m.d.c))
        c9 = next_gen(join(m.d.a, m.d.b, m.d.c, m.d.d))
        
        s = join(
            (join(c1.d, c2.c, c4.b, c5.a)),
            (join(c2.d, c3.c, c5.b, c6.a)),
            (join(c4.d, c5.c, c7.b, c8.a)),
            (join(c5.d, c6.c, c8.b, c9.a)),
        )                    
    return s
```
However, this is much less efficient than the true Hashlife algorithm, which computes $2^{k-2}$ steps into the future for a level $k$ input. The code to do this is almost the same but has a double recursion:

```python
@lru_cache(maxsize=2**24)
def successor(m):    
    """Return the 2**k-1 x 2**k-1 successor, 2**k-2 generations forward"""    
    if m.n==0: # empty
        return m.a    
    elif m.k == 2:  # base case               
        s = life_4x4(m)    
    else:
        c1 = successor(join(m.a.a, m.a.b, m.a.c, m.a.d))
        c2 = successor(join(m.a.b, m.b.a, m.a.d, m.b.c))
        c3 = successor(join(m.b.a, m.b.b, m.b.c, m.b.d))
        c4 = successor(join(m.a.c, m.a.d, m.c.a, m.c.b))        
        c5 = successor(join(m.a.d, m.b.c, m.c.b, m.d.a))
        c6 = successor(join(m.b.c, m.b.d, m.d.a, m.d.b))
        c7 = successor(join(m.c.a, m.c.b, m.c.c, m.c.d))
        c8 = successor(join(m.c.b, m.d.a, m.c.d, m.d.c))
        c9 = successor(join(m.d.a, m.d.b, m.d.c, m.d.d))

        # recurse again, inside each sub-element
        s = join(
            successor(join(c1, c2, c4, c5)),
            successor(join(c2, c3, c5, c6)),
            successor(join(c4, c5, c7, c8)),
            successor(join(c5, c6, c8, c9)),
        )   
    return s
```

The problem here is that if we wanted to compute some smaller jump forward, there is no easy way to do so. Adding a parameter `j` allows a skip by any power of 2 smaller or equal to $2^{k-2}$.

```python
@lru_cache(maxsize=2**24)
def successor(m, j=None):
    """Return the 2**k-1 x 2**k-1 successor, 2**j generations in the future"""        
    if m.n==0: # empty
        return m.a    
    elif m.k == 2:  # base case               
        s = life_4x4(m)    
    else:        
        c1 = successor(join(m.a.a, m.a.b, m.a.c, m.a.d), j)
        c2 = successor(join(m.a.b, m.b.a, m.a.d, m.b.c), j)
        c3 = successor(join(m.b.a, m.b.b, m.b.c, m.b.d), j)
        c4 = successor(join(m.a.c, m.a.d, m.c.a, m.c.b), j)        
        c5 = successor(join(m.a.d, m.b.c, m.c.b, m.d.a), j)
        c6 = successor(join(m.b.c, m.b.d, m.d.a, m.d.b), j)
        c7 = successor(join(m.c.a, m.c.b, m.c.c, m.c.d), j)
        c8 = successor(join(m.c.b, m.d.a, m.c.d, m.d.c), j)
        c9 = successor(join(m.d.a, m.d.b, m.d.c, m.d.d), j)
        
        if j is not None and j < m.k - 2:
            return join(
                (join(c1.d, c2.c, c4.b, c5.a)),
                (join(c2.d, c3.c, c5.b, c6.a)),
                (join(c4.d, c5.c, c7.b, c8.a)),
                (join(c5.d, c6.c, c8.b, c9.a)),
            )    
        else:
            return join(
            successor(join(c1, c2, c4, c5), j),
            successor(join(c2, c3, c5, c6), j),
            successor(join(c4, c5, c7, c8), j),
            successor(join(c5, c6, c8, c9), j),
        )                   
    return s
```


* **advance(node, n)** find the `n`th successor of a given node. Since we compute any advance step of $2^j$, up to $2^{k-2}$, of a level $k$ node, we can advance by any $n$ by using the binary expansion of $n$ to find the successor. 

```python
def advance(node, n):        
    if n==0:
        return node    
    
    # get bits and make sure we've nested deep enough
    bits = []    
    while n > 0:
        bits.append(n & 1)
        n = n >> 1
        node = centre(node)        
    
    for k, bit in enumerate(reversed(bits)):
        j = len(bits) - k  - 1        
        if bit:
            node = variable_step(node, j)
    return node
```

* **ffwd(node, n)** if we just want to simulate as fast as possible, we can use `ffwd` to jump forward as quickly as possible:

```python
def ffwd(node, n):    
    for i in range(n):       
        while (node.k < 3 or node.a.n != node.a.d.d.n or
                node.b.n != node.b.c.c.n or
                node.c.n != node.c.b.b.n or
                node.d.n != node.d.a.a.n):
                node = centre(node)    
        node = variable_step(node, None)
    return node
```

### Auxiliary routines

We need to be able to pack and unpack data to/from quadtree format. `expand` and `construct` can transform nodes to/from `(x,y)` point lists.


* **expand(node, clip=None, level=0)** transform a quadtree into a list of (x,y) cell coordinates that fall inside a given clipping window (e.g. for display). `level` allows us to
report the average occupancy of quadtree leaves without fully recursing into them.

```python
def expand(node, x=0, y=0, clip=None, level=0):
    """Turn a quadtree a list of (x,y,gray) triples 
    in the rectangle (x,y) -> (clip[0], clip[1]) (if clip is not-None).    
    If `level` is given, quadtree elements at the given level are given 
    as a grayscale level 0.0->1.0,  "zooming out" the display."""
    
    if node.n==0: # quick zero check
        return []    
    size = 2 ** node.k
    # bounds check
    if clip is not None:
        if x + size < clip[0] or x > clip[1] or 
           y + size < clip[2] or y > clip[3]:
            return []
    if node.k == level:
        # base case: return the gray level of this node
        gray = node.n / (size ** 2)
        return [(x >> level, y >> level, gray)] if node.n > 0 else []
    else:
        # return all points contained inside this cell
        offset = size >> 1
        return (
            expand(node.a, x=x, y=y, clip=clip, level=level)
            + expand(node.b, x=x + offset, y=y, clip=clip, level=level)
            + expand(node.c, x=x, y=y + offset, clip=clip, level=level)
            + expand(node.d, x=x + offset, y=y + offset, clip=clip, level=level)
        )        
```        

* **construct(cells)** convert a set of (x,y) coordinates into a quadtree node by recursively merging blocks together.

```python
def construct(pt_list):
    """Turn a list of (x,y) coordinates into a quadtree"""
    # Force start at (0,0)
    min_x = min(*[x for x, y in pt_list])
    min_y = min(*[y for x, y in pt_list])
    pattern = {(x - min_x, y - min_y): on for x, y in pt_list}
    k = 0
    while len(pattern) != 1:
        # bottom-up construction
        next_level = {}
        z = get_zero(k)
        while len(pattern) > 0:
            x, y = next(iter(pattern))
            x_q, y_q = x - (x & 1), y - (y & 1)
            # read all 2x2 neighbours, removing from those to work through
            # at least one of these must exist by definition
            a = pattern.pop((x_q, y_q), z)
            b = pattern.pop((x_q + 1, y_q), z)
            c = pattern.pop((x_q, y_q + 1), z)
            d = pattern.pop((x_q + 1, y_q + 1), z)
            next_level[x_q >> 1, y_q >> 1] = join(a, b, c, d)
        # merge at the next level
        pattern = next_level
        k += 1
    return pattern.popitem()[1]
```

## Testing

Using some utility functions from `lifeparsers.py` to load standard Life patten formats, we can verify that this works:

```python
    from lifeparsers import autoguess_life_file

    def load_lif(fname):
        pat, comments = autoguess_life_file(fname)
        return construct(pat)
```

```python
    >>> ffwd(load_lif("lifep/breeder.lif"), 8)
    (Node k=42, 4398046511104 x 4398046511104, population 25185954567301246087084,
 4398046510080)
```

This took 883ms (!) to compute 4398046510080 generations into the future on my machine. We can inspect the caches:

```python
    >>> variable_step.cache_info()
    CacheInfo(hits=504184, misses=52222, maxsize=16777216, currsize=52222)
```

```python
    >>> join.cache_info()
    CacheInfo(hits=561324, misses=52246, maxsize=16777216, currsize=52246)
```

We can check it is doing the right thing for smaller steps, too:

```python
pat = load_lif("lifep/gun30.lif")
show_gray(expand(pat))
show_gray(expand(advance(centre(centre(pat)), 30)))
```





## References

[#Gosper1984]: Gosper, Bill (1984). "Exploiting Regularities in Large Cellular Spaces". Physica D. Elsevier. 10 (1–2): 75–80. doi:10.1016/0167-2789(84)90251-3.


[John H Williamson](https://johnhw.github.io)

[GitHub](https://github.com/johnhw) / [@jhnhw](https://twitter.com/jhnhw)

<link rel="stylesheet" href="../global/style.css" type="text/css" ></link>
<script>
window.markdeepOptions = {tocStyle:'none'};</script>
<!-- Markdeep: --><style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="markdeep.min.js" charset="utf-8"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js" charset="utf-8"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>